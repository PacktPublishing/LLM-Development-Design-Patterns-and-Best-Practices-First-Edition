{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Fairness-Aware Classification with Fairlearn\n",
        "This notebook shows how to apply fairness constraints to a machine learning model using Fairlearn, focusing on Demographic Parity and the Exponentiated Gradient reduction algorithm."
      ],
      "metadata": {
        "id": "YRR3GTWjnwb8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCu3HkzWnmWT"
      },
      "outputs": [],
      "source": [
        "! pip install fairlearn scikit-learn numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1: Import Required Libraries"
      ],
      "metadata": {
        "id": "iBHc5OrQnyfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_classification\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "NudpANNxno4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Generate Synthetic Data\n",
        "We generate a binary classification dataset and add a synthetic sensitive feature (e.g., gender)."
      ],
      "metadata": {
        "id": "k28oTz_pn3X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a toy classification dataset\n",
        "X, y = make_classification(n_samples=500, n_features=5, random_state=42)\n",
        "\n",
        "# Create a synthetic sensitive feature (e.g., gender: 0 = Male, 1 = Female)\n",
        "sf = np.random.randint(0, 2, size=500)\n"
      ],
      "metadata": {
        "id": "ZG72wWIKn3K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Train-Test Split\n",
        "We'll use 400 samples for training and the rest for testing."
      ],
      "metadata": {
        "id": "ETcIcj9in83f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and test sets\n",
        "X_train, y_train, sf_train = X[:400], y[:400], sf[:400]\n",
        "X_test, y_test, sf_test = X[400:], y[400:], sf[400:]\n"
      ],
      "metadata": {
        "id": "Ygk7CxARn8pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Define the Base Estimator\n",
        "We'll use a simple logistic regression model as the base learner."
      ],
      "metadata": {
        "id": "1J-dbLVroCj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base classifier\n",
        "estimator = LogisticRegression(solver=\"liblinear\")"
      ],
      "metadata": {
        "id": "9TYdyVw9oCYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Define the Fairness Constraint\n",
        "We'll apply the Demographic Parity constraint, with a small allowed difference (0.01) between groups."
      ],
      "metadata": {
        "id": "0liTsVV_oIK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define fairness constraint: Demographic Parity\n",
        "constraint = DemographicParity(difference_bound=0.01)"
      ],
      "metadata": {
        "id": "CzMjL3XzoCR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Initialize the Fairness Mitigator\n",
        "Wrap the base estimator with the ExponentiatedGradient algorithm to enforce fairness."
      ],
      "metadata": {
        "id": "8wU3-vRZoNEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a fairness-aware model wrapper\n",
        "mitigator = ExponentiatedGradient(estimator, constraint)\n"
      ],
      "metadata": {
        "id": "YUNbMagmoCK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Train the Fair Model\n",
        "Now we train the fairness-constrained model, providing the sensitive feature alongside the training data."
      ],
      "metadata": {
        "id": "nMhd3-APoSQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the fairness-constrained model\n",
        "mitigator.fit(X_train, y_train, sensitive_features=sf_train)"
      ],
      "metadata": {
        "id": "LsXj9t5koSFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the code does not print output by default, you can evaluate the fairness of predictions like this:\n"
      ],
      "metadata": {
        "id": "hrFOkHsFp1Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate predicted outcomes on training data\n",
        "y_pred = mitigator.predict(X_train)\n",
        "\n",
        "\n",
        "# Check proportion of positive predictions by group\n",
        "group_0 = y_pred[sf_train == 0]\n",
        "group_1 = y_pred[sf_train == 1]\n",
        "\n",
        "\n",
        "print(\"Positive outcome rate for Group 0:\", group_0.mean())\n",
        "print(\"Positive outcome rate for Group 1:\", group_1.mean())"
      ],
      "metadata": {
        "id": "vorvhe4np0ho"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}